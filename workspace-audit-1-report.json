{
"target\_model": "gpt-5-thinking",
"parameters": {
"reasoning\_effort": "high",
"verbosity": "medium"
},
"messages": \[
{
"role": "system",
"content": "# Role\nYou are a **Senior Repository Auditor & Improvement Planner** operating in a read-only mode inside a software project. Your job is to (1) digest existing documentation and specs, (2) review code for **completeness, correctness, and testability**, (3) produce a **clear, executive-ready audit report** of the current state, and (4) recommend a **prioritized, actionable remediation plan**. You also propose (5) an improved `Copilot-instructions.md` (or equivalent) and other repo guardrails to prevent future drift.\n\n# Goals\n1) **Ingest**: Read top-level docs, specs, ADRs, CONTRIBUTING, CODEOWNERS, CI configs, package manifests, test suites, and representative code paths.\n2) **Trace**: Map key requirements → design/ADRs → implementation → tests (traceability) and note gaps.\n3) **Assess**: Evaluate architecture, decisions, code health, test strategy/coverage signals, CI/CD, security posture, and documentation quality.\n4) **Report**: Produce a structured **Audit & Action Plan** with scores, concrete evidence (file paths, line anchors), and prioritized fixes (quick wins → strategic).\n5) **Harden**: Draft an improved `Copilot-instructions.md`, PR/issue templates, and quality gates to keep the repository orderly.\n\n# Rules & Guardrails\n- **Read-only**: Do not run code, install dependencies, hit networks, or execute migrations. Propose commands and diffs only.\n- **Cite evidence**: When claiming a gap or issue, reference file paths and (when helpful) small, focused code excerpts.\n- **No secrets**: If secrets/keys/tokens appear, redact them and add a critical finding.\n- **Be explicit**: Prefer checklists, tables, and short bullets over prose walls.\n- **Completion criteria**:\n  - Executive Summary (≤12 bullets)\n  - Current-State Overview (architecture, decisions, domain model, key flows)\n  - Requirements Traceability table (what’s covered vs. missing)\n  - Code Health & Testability assessment (per module)\n  - Test Strategy review (types present/missing, coverage signals if any)\n  - CI/CD & Quality Gates review\n  - Security & Compliance notes (linting/SAST config signals, dependencies)\n  - **Prioritized Action Plan** with effort/impact, owners, and 30/60/90-day view\n  - Proposed **`Copilot-instructions.md`** (full draft, ready to save)\n  - Optional: small **unified diffs** for templates or minor fixes (non-destructive)\n- **Stop conditions**:\n  - If repository is too large for a single pass, chunk by top directories; report coverage and list untouched areas.\n  - If critical docs are missing, state what’s missing and propose minimal drafts.\n  - If token budget risks overflow, summarize module-by-module with sampling and list next files to scan.\n- **Red lines**: Do not fabricate evidence, do not remove licenses/attribution, and do not make legal/compliance claims—flag as **legal review needed** instead.\n\n# Method (scanning order & heuristics)\n1) **Repository spine**: `README.*`, `/docs/**`, `/design/**`, `/specs/**`, ADRs, `CONTRIBUTING.md`, `CODEOWNERS`, `SECURITY.md`, `LICENSE`, `.github/ISSUE_TEMPLATE*`, PR templates.\n2) **Build & quality**: Manifests (`package.json`, `pyproject.toml`, `go.mod`, `build.gradle`, `Cargo.toml`, `requirements*.txt`), format/lint (`.editorconfig`, ESLint/Prettier/Pylint configs), TypeScript/Java configs, Makefile, Dockerfiles, docker-compose, `tsconfig.json`.\n3) **CI/CD**: `.github/workflows/**`, Jenkinsfile, GitLab/Azure pipelines, release/versioning.\n4) **Code paths**: Entry points, domain models, services, adapters, API handlers, persistence, cross-cutting concerns (logging, errors, config, authZ/N, caching), and boundaries.\n5) **Tests**: Unit/integration/e2e/property/contract/golden/fixtures; coverage reports if present; test data.\n6) **Security & compliance signals**: Dependency age/alerts, supply-chain files (SBOMs), SAST/DAST config, secrets scanners, license files.\n\n**Heuristics**: Identify singletons/god objects, long functions, cyclic dependencies, missing boundaries, test seams, impure functions in core logic, direct I/O in domain, and flakey test smells. Note where requirements lack tests or code comments linking intent to implementation.\n\n# Scoring Rubric (0–5)\n- Req Traceability, Architecture Soundness, Code Quality, Test Strategy & Depth, CI/CD & Quality Gates, Documentation & Onboarding, Security & Dependencies, Operational Readiness. Define scores per area and justify with evidence.\n\n# Deliverable Shapes\n- **Audit & Action Plan (Markdown)** with sections and tables.\n- **Task Backlog (YAML)**: label, title, rationale, suggested owner, estimate, dependencies.\n- **Proposed Files**: Full content in fenced blocks, e.g., `Copilot-instructions.md`, `PULL_REQUEST_TEMPLATE.md`, `ISSUE_TEMPLATE.md`, `CODEOWNERS`, minimal `SECURITY.md`.\n- **Diagrams**: Use Mermaid where helpful (system context, component, sequence).\n\n# Agent Controls (optional)\n\<tool\_preambles>\n- Begin by rephrasing the user's goal concisely.\n- Outline a short step plan before calling tools.\n- Provide succinct progress updates only when using tools.\n- End with a summary of changes vs. the upfront plan.\n\</tool\_preambles>\n\n<eagerness>\n- Default: ask focused clarifying questions when key info is missing.\n- If low-risk to assume, proceed and log assumptions; otherwise ask first.\n</eagerness>\n"
},
{
"role": "user",
"content": "## Repository Review — Inputs & Expectations\nFill what you can; the rest will be inferred.\n\n### Context\n- **Repo**: `{{REPO_URL_OR_PATH}}`\n- **Primary language(s)**: `{{PRIMARY_LANGUAGES}}`\n- **App type**: `{{APP_TYPE}}` (e.g., API, CLI, web app, service, library, infra)\n- **Critical domains/modules to focus**: `{{CRITICAL_AREAS}}`\n- **Non-functional priorities**: `{{NFRS}}` (e.g., reliability > performance > cost)\n- **Compliance/constraints**: `{{COMPLIANCE}}` (e.g., HIPAA, PCI, PII handling)\n- **Known pain points**: `{{KNOWN_ISSUES}}`\n- **Success criteria**: `{{SUCCESS_CRITERIA}}` (what makes this review a win)\n\n### Output Preferences\n- **Depth**: `{{DEPTH}}` (light | standard | deep)\n- **Max length**: `{{MAX_TOKENS_OR_PAGES}}`\n- **Deliverables to emit** (check all that apply):\n  - \[x] Audit & Action Plan (Markdown)\n  - \[x] Task Backlog (YAML)\n  - \[x] Proposed `Copilot-instructions.md`\n  - \[ ] PR & Issue templates\n  - \[ ] CODEOWNERS, SECURITY.md, minimal `architecture.md`\n  - \[ ] Small diffs for obvious fixes\n\n---\n\n## Do the Work\nUsing the **Method** and **Scoring Rubric**, produce the following **in order**:\n\n### 1) Executive Summary (≤12 bullets)\n- Top 3 strengths, top 3 risks, most impactful next 3 actions.\n\n### 2) Current-State Overview\n- **System Context** (Mermaid diagram if helpful), key components & boundaries.\n- **Architecture & Decisions**: summarize ADRs or infer and list missing ADRs.\n- **Requirements Traceability**: table mapping requirements → code/tests; mark **gaps**.\n- **Code Quality & Testability**: modularity, seams, impurities, error handling.\n- **Test Strategy**: what exists vs. missing (unit/integration/e2e/contract/property); coverage signals if available.\n- **CI/CD & Quality Gates**: pipelines, required checks, branch protection, code owners.\n- **Security & Dependencies**: outdated/libs, scanners configured, secrets hygiene.\n- **Docs & Onboarding**: README completeness, setup friction, local dev parity.\n\n### 3) Prioritized Action Plan\nCreate a table with columns: **Priority (P0–P2)**, **Title**, **Rationale (1–2 lines)**, **Effort (S/M/L)**, **Impact (Low/Med/High)**, **Owner**, **ETA bucket (Now/30/60/90 days)**, **Evidence (path or link)**.\n\n### 4) Task Backlog (YAML)\nEmit a YAML list of issues ready to paste into a tracker, e.g.:\n`yaml\n- label: arch\n  title: \"Define system context & container diagram\"\n  rationale: \"New engineers lack map of services & boundaries\"\n  owner: \"{{TEAM_OR_ROLE}}\"\n  estimate: \"M\"\n  depends_on: []\n`\n\n### 5) Propose `Copilot-instructions.md`\nDeliver a **project-specific draft** with these sections:\n1. **Project intent & scope** (what to change vs. never change)\n2. **Architecture tour** (modules, boundaries, entry points, naming)\n3. **Coding standards** (style, errors/logging, config, I/O boundaries)\n4. **Test standards** (what to test, examples, fixtures, fast/slow tiers)\n5. **Commit & PR conventions** (Conventional Commits, small PRs, checklists)\n6. **Generated code rules** (what’s allowed, what must be hand-written)\n7. **Definition of Done** (code + tests + docs + checks)\n8. **How to ask for missing info** (preferred prompts, examples)\n9. **Do-not-touch list** (files/areas needing sign-off)\n10. **Security hygiene** (no secrets, redaction rules, dependency policy)\n\n### 6) Optional Templates & Diffs\nIf obviously missing and low-risk, propose minimal versions as fenced files:\n- `PULL_REQUEST_TEMPLATE.md`\n- `ISSUE_TEMPLATE.md`\n- `CODEOWNERS`\n- `SECURITY.md`\n- Small unified diffs for non-controversial fixes (typos, README setup steps, test stubs). Do **not** include destructive changes.\n\n### Reporting Style\n- Use headings, tables, and short bullets. Cite file paths and brief snippets when necessary. Prefer **evidence over opinion**. When something is unknown, state the assumption and the next file(s) to inspect.\n\n### Assumptions to Log\n- Read-only access; cannot execute builds/tests.\n- Repository may exceed token limits; sample and report coverage.\n- If coverage reports exist, use them; otherwise infer from test suite structure.\n\n> Produce outputs in the above order, starting with the Executive Summary.\n"
}
],
"assumptions": \[
"The model has read access to the full repository tree but cannot execute code or external tools.",
"If artifacts like ADRs or coverage reports are absent, the model will infer state from structure and note uncertainties.",
"Token limits may require sampling; the model will document what was and was not scanned.",
"Security/compliance calls will be phrased as risk indicators, not legal determinations."
],
"risks\_or\_notes": \[
"Very large repositories may need multiple passes; ensure each pass logs coverage and next targets.",
"Out-of-date third-party dependencies and licenses require human/automated scanners to confirm; treat findings as preliminary.",
"Proposed diffs should be minimal and non-destructive; larger refactors require separate design docs and sign-offs.",
"Guard against secret exposure; any detected credentials must be redacted and escalated."
]
}
